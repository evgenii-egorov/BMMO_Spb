# BMMO_Spb
Лектор _[Dmitriy Vetrov](https://www.hse.ru/staff/dvetrov)_

Семинаристы: [Evgenii Egorov](https://scholar.google.ru/citations?user=LwVVunEAAAAJ), [Denis Rakitin](https://www.hse.ru/org/persons/190910999)

По вопросам, пишите: [Evgenii Egorov](mailto:egorov.evgenyy@ya.ru), [Denis Rakitin](mailto:rakitindenis32@gmail.com), тема письма: [Spb BMMO].

## Notifications channel
Все объявления и оповещения по курсу публикаются в телеграмм-канале: https://t.me/joinchat/AAAAAEbrvkgUhTmvuiOL1Q

## Zoom
- Meeting ID: 378 227 0028 
- Passcode: смотрите Notifications channel

## Homeworks
- 2 практических домашних задания
- 3 теоретических домашних задания
- 4 домашних лабораторных работы

Каждое задание весит по 10 баллов.
Информация о подсчете общего числа баллов и о способе сдачи домашек появится позже.

## Dates-Materials Table
Стартуем каждый четверг с 16-00:17-30 (Moscow time), планируйте занятость до 18. Пожалуйста, не опаздывайте: лучше подключится к зум встрече немного раньше.

## Dates-Materials Table
Стартуем каждый четверг с 16-00:17-30 (Moscow time), планируйте занятость до 18. Пожалуйста, не опаздывайте: лучше подключится к зум встрече немного раньше.

| Дата  | Тема                                                                                                                                                                           | Материалы лекций | Материалы семинара | Zoom запись |
|-------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------|--------------------|--------------------------|
| 1 Окт | 1. Байесовский подход к теории вероятностей, примеры байесовских рассуждений <br> 2. Аналитический байесовский вывод, сопряжённые распределения, экспоненциальный класс распределений | 1.: [презентация](https://bayesgroup.github.io/bmml/2016/Lectures/lecture01_presentation.pdf), [конспект](https://drive.google.com/open?id=13Q58mRGh5uN8xyhMiTfoOXOYvxUKbvRY), [саммари](https://bayesgroup.github.io/bmml/2016/Lectures/lecture01_summary.pdf), [видео](https://youtu.be/Ejsr3S79gcQ?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw) <br> 2.:  [конспект](https://drive.google.com/file/d/1g9cNLw85MchawKbSV7F0nUXyEi9m36sR/view?usp=sharing), [видео](https://youtu.be/xaPIlAAyFvY?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)                | 1.: [задачи](https://bayesgroup.github.io/bmml/2016/Seminars/BMML_sem1_2016.pdf) <br> 2.: [задачи](http://bayesgroup.github.io/bmml/2016/Seminars/BMML_sem2_2016.pdf), [ноутбук (open with -> colab)](https://drive.google.com/file/d/13Pgt239Z2NxIyxeoqlRfRgEp_21CX8lO/view)                  |                  [Семинар 1](https://youtu.be/bv9j5ocGVrU)        |
| 8 Окт |  Задача выбора модели по Байесу, принцип наибольшей обоснованности, примеры выбора вероятностной модели                                                                       |   [презентация](http://www.machinelearning.ru/wiki/images/b/bd/BMMO11_5.pdf), [конспект](https://drive.google.com/file/d/1l8fhZQ5V60wZaL9n_YlKNESW1y01PtX2/view?usp=sharing), [видео](https://youtu.be/QuDDPviPEb4?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)         |[Seminar notes](https://drive.google.com/file/d/18M0hT1Vzjyh4l4_ldc961cU1xauH7sNF/view?usp=sharing)                  |  [Семинар 2](https://youtu.be/R8oLVPY0iPU)                        | 
| 15 Окт | Метод релевантных векторов для задачи регрессии, автоматическое определение значимости. Матричные вычисления.                                                                  |  [презентация](https://bayesgroup.github.io/bmml/2016/Lectures/lecture04_presentation.pdf), [конспект](https://drive.google.com/file/d/1wr6qJCZPZ5W2s4jdJRpoFO_E2J3oPPP1/view?usp=sharing), [видео](https://youtu.be/Q65APl9MFTs?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)                |                    |       [zoom record](https://youtu.be/5sSyxJ-zytA)      | 
| 22 Окт | Метод релевантных векторов для задачи классификации, приближение Лапласа.                                                                                                      | [презентация](http://www.machinelearning.ru/wiki/images/6/6c/BMMO11_8.pdf), [конспект](https://drive.google.com/file/d/1cDEShfLPKXSc-OPUXm4nCYZLPvzaBVHg/view?usp=sharing), [видео](https://youtu.be/AiLg8WuiEUc?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)                 |                    [слайды](https://drive.google.com/file/d/1ezz6LXef6pFdbljSvvZIlnmYqietQg-s/view?usp=sharing), [ноутбук с реализацией RVM](https://drive.google.com/file/d/1uo801rSmM61QqoR99hFVgltB5T9GDyn9/view?usp=sharing), [ноутбук с реализацией sequential learning](https://drive.google.com/file/d/19siYDyImkCc2-XF8xWrldwCPFjmrF1jl/view?usp=sharing), [notes](https://drive.google.com/file/d/1QV46BKJiD3il3RvrrMYb6dnkplHmwn9r/view?usp=sharing)           | [zoom record](https://youtu.be/0wK18WQornM)|
| 29 Окт | Обучение при скрытых переменных, ЕМ-алгоритм в общем виде, байесовская модель метода главных компонент.                                                                        | [презентация](http://www.machinelearning.ru/wiki/images/7/73/BMMO11_11.pdf), [конспект](https://drive.google.com/file/d/13bmPc3sJJLgN45j75DqlcBgEzqL2u4Rv/view?usp=sharing), [видео](https://youtu.be/YQHw7KZUWt8?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)             |     [конспект](https://drive.google.com/file/d/1aZhKJtD1_4eN3gn4dx7otbO5IbZO4lr3/view?usp=sharing)               |  [partial zoom record](https://youtu.be/zUnyqMCRhfc)           |
| 5 Ноя  | Вариационный подход для приближённого байесовского вывода.                                                                                                                     |  [презентация](http://www.machinelearning.ru/wiki/images/5/57/BMMO11_9.pdf), [конспект](https://drive.google.com/file/d/18UP8ic6lq1DOOJZlKfGhHr46PJAb6oMY/view?usp=sharing), [видео](https://youtu.be/JdBOFNDDhuY?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)                 |      [notes](https://drive.google.com/file/d/1NPnF3RjPd2XxTBz0aKclbh1wGVzez-ej/view?usp=sharing)              |    [zoom record](https://youtu.be/q-mF4zJ_XOU)         |
| 12 Ноя | Методы Монте-Карло с марковскими цепями (MCMC).                                                                                                                                |                  |                    |             |
| 19 Ноя | Гибридный метод Монте-Карло с марковскими цепями и его масштабируемые обобщения.                                                                                               |                  |                    |             |
| 26 Ноя | Гауссовские процессы для регрессии и классификации.                                                                                                                            |                  |                    |             |
| 3 Дек  | Модель LDA для тематического моделирования.                                                                                                                                    |                  |                    |             |
| 10 Дек | Стохастический вариационный вывод. Вариационный автокодировщик                                                                                                                 |                  |                    |             |
| 17 Дек | Заключительный семинар                                                                                                                                                         |                  |                    |             |



## Materials  
- Официальный [конспект лекций](https://drive.google.com/file/d/1KHB2lXKg7pOXRaYzbu7tMyV5Nmz84jHZ/view?usp=sharing) в процессе (пока сделано до 3 лекции включительно, будет пополняться)
- [Видео записи лекций](https://www.youtube.com/playlist?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)

### Links 
- [Сайт одноименного курса](http://www.machinelearning.ru/wiki/index.php?title=Bmmo), читаемого на ВМК МГУ. 
- [Сайт группы Байесовских методов](http://bayesgroup.ru/).
- Простые и удобные [заметки](http://cs.nyu.edu/~roweis/notes.html) по матричным вычислениям и свойствам гауссовских распределений. 
- [Памятка](http://statistics.zone/) по теории вероятностей.
